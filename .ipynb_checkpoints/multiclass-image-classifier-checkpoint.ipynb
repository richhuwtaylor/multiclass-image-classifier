{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# multi-class-image-classifier\n",
    "\n",
    "Take a CNN pretrained on ImageNet, remove the last fully-connected layer, then treat the rest of the ConvNet as a fixed feature extractor for a much smaller dataset. (Note: this doesn't involve any actual tuning of the weights of the pre-trained network by continuing backprop, which might be a better strategy). \n",
    "\n",
    "Use the pre-trained ImageNet weights of the [VGG16 deep learning model](https://arxiv.org/abs/1409.1556) for multi-class image classification. The process consists of the following steps:\n",
    "\n",
    "1. Save the \"bottleneck\" features from the VGG16 model.\n",
    "2. Train a small network using the saved bottleneck features to classify images, and save the model (this is known as the \"top model\").\n",
    "3. Use both the VBB16 model and the top model to make predictions.\n",
    "\n",
    "## About the data\n",
    "This notebook makes use of the ImageDataGenerator and flow_from_directory functionality of Keras, so the data directory structure is such that each class sits within its own sub-directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img  \n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Dropout, Flatten, Dense  \n",
    "from keras import applications  \n",
    "from keras.utils.np_utils import to_categorical  \n",
    "import matplotlib.pyplot as plt  \n",
    "import math\n",
    "import h5py as h5py\n",
    "\n",
    "# not strictly necessary - used to display the result of a prediction\n",
    "import cv2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Top Model Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# image dimensions:\n",
    "img_width, img_height = 224, 224  \n",
    "\n",
    "# file paths:\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'  \n",
    "train_data_dir = 'data/train'  \n",
    "validation_data_dir = 'data/validation'  \n",
    "\n",
    "# number of epochs to train the top model:\n",
    "epochs = 50  \n",
    "# batch size used by flow_from_directory and predict_generator:  \n",
    "batch_size = 16 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Function for saving bottleneck features from the VGG16 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_bottlebeck_features():\n",
    "    # build the VGG16 network, pre-trained on imagenet, but without the\n",
    "    # final fully-connected layers (specified by include_top = False)\n",
    "    model = applications.VGG16(include_top = False,\n",
    "                               weights = 'imagenet')\n",
    "\n",
    "    datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    # takes a path to a directory and generates batches of data\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size = (img_width, img_height),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = None,\n",
    "        shuffle = False)\n",
    "\n",
    "    nb_train_samples = len(generator.filenames)\n",
    "    num_classes = len(generator.class_indices)\n",
    "    \n",
    "    print(nb_train_samples)\n",
    "    print(generator.class_indices)\n",
    "    print(num_classes)\n",
    "\n",
    "    # number of batches to train on\n",
    "    # necessary because of a bug in predict_generator where it can't \n",
    "    # determine the correct number of iterations when the number of \n",
    "    # training samples isn't divisible by the batch size\n",
    "    predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "\n",
    "    # generate predictions by running generator on VGG16 model to get\n",
    "    # bottleneck features for training\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, predict_size_train)\n",
    "\n",
    "    np.save('bottleneck_features_train.npy', bottleneck_features_train)\n",
    "\n",
    "    # do the same as above, but for the validation samples\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size = (img_width, img_height),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = None,\n",
    "        shuffle = False)\n",
    "\n",
    "    nb_validation_samples = len(generator.filenames)\n",
    "\n",
    "    predict_size_validation = int(\n",
    "        math.ceil(nb_validation_samples / batch_size))\n",
    "\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, predict_size_validation)\n",
    "\n",
    "    np.save('bottleneck_features_validation.npy',\n",
    "            bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Function for training the top model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    # create a generator for fetching the class labels for each of the\n",
    "    # training/validation samples (class_mode = 'categorical')\n",
    "    datagen_top = ImageDataGenerator(rescale = 1./255)\n",
    "    \n",
    "    generator_top = datagen_top.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size = (img_width, img_height),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'categorical',\n",
    "        shuffle = False)\n",
    "\n",
    "    nb_train_samples = len(generator_top.filenames)\n",
    "    num_classes = len(generator_top.class_indices)\n",
    "\n",
    "    # save the class indices to use use later in predictions\n",
    "    np.save('class_indices.npy', generator_top.class_indices)\n",
    "\n",
    "    # load the bottleneck features saved earlier\n",
    "    train_data = np.load('bottleneck_features_train.npy')\n",
    "\n",
    "    # get the class labels for the training data, in the original order\n",
    "    train_labels = generator_top.classes\n",
    "\n",
    "    # https://github.com/fchollet/keras/issues/3467\n",
    "    # convert the training labels to categorical vectors\n",
    "    train_labels = to_categorical(train_labels, num_classes = num_classes)\n",
    "\n",
    "    # do the same as above for the validation features\n",
    "    generator_top = datagen_top.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size = (img_width, img_height),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = None,\n",
    "        shuffle = False)\n",
    "\n",
    "    nb_validation_samples = len(generator_top.filenames)\n",
    "\n",
    "    validation_data = np.load('bottleneck_features_validation.npy')\n",
    "\n",
    "    # convert the validation labels into a binary class matrix\n",
    "    # (necessary for use with categorical_crossentropy loss function)\n",
    "    validation_labels = generator_top.classes\n",
    "    validation_labels = to_categorical(\n",
    "        validation_labels, num_classes = num_classes)\n",
    "\n",
    "    ### THE NETWORK ###\n",
    "    # create and train a small fully-connected network (the top model)\n",
    "    # using the bottleneck features as input, outputs the classifier\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape = train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(optimizer = 'rmsprop',\n",
    "                  loss = 'categorical_crossentropy', \n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "    # fit the model to the training samples, evaluating the loss and metrics\n",
    "    # on the validation data\n",
    "    history = model.fit(train_data, train_labels,\n",
    "                        epochs = epochs,\n",
    "                        batch_size = batch_size,\n",
    "                        validation_data = (validation_data, validation_labels))\n",
    "\n",
    "    model.save_weights(top_model_weights_path)\n",
    "\n",
    "    (eval_loss, eval_accuracy) = model.evaluate(\n",
    "        validation_data, validation_labels,\n",
    "        batch_size = batch_size, verbose = 1)\n",
    "\n",
    "    print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
    "    print(\"[INFO] Loss: {}\".format(eval_loss))\n",
    "\n",
    "    plt.figure(1)\n",
    "\n",
    "    # graph the training history for clarity:\n",
    "    \n",
    "    # summarise history for accuracy\n",
    "    plt.subplot(211)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc = 'upper left')\n",
    "\n",
    "    # summarise history for loss\n",
    "    plt.subplot(212)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc = 'upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Function for making predictions from the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict():\n",
    "    # load the class_indices saved during training\n",
    "    class_dictionary = np.load('class_indices.npy').item()\n",
    "\n",
    "    num_classes = len(class_dictionary)\n",
    "\n",
    "    # path to test image:\n",
    "    image_path = 'data/eval/test-image-goes-here'\n",
    "\n",
    "    orig = cv2.imread(image_path)\n",
    "\n",
    "    print(\"[INFO] loading and preprocessing image...\")\n",
    "    image = load_img(image_path, target_size = (224, 224))\n",
    "    image = img_to_array(image)\n",
    "\n",
    "    # rescale the image in the same way as the training data\n",
    "    image = image / 255\n",
    "\n",
    "    image = np.expand_dims(image, axis = 0)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top = False,\n",
    "                               weights = 'imagenet')\n",
    "\n",
    "    # get the bottleneck prediction from the pre-trained VGG16 model\n",
    "    bottleneck_prediction = model.predict(image)\n",
    "\n",
    "    # build top model\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=bottleneck_prediction.shape[1:]))\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation = 'sigmoid'))\n",
    "\n",
    "    model.load_weights(top_model_weights_path)\n",
    "\n",
    "    # use the bottleneck prediction on the top model to get the final\n",
    "    # classification\n",
    "    class_predicted = model.predict_classes(bottleneck_prediction)\n",
    "\n",
    "    probabilities = model.predict_proba(bottleneck_prediction)\n",
    "\n",
    "    inID = class_predicted[0]\n",
    "\n",
    "    # it's easier to work with a dictionary with index as key and label\n",
    "    # as value, so invert the labels map:\n",
    "    inv_map = {v: k for k, v in class_dictionary.items()}\n",
    "\n",
    "    label = inv_map[inID]\n",
    "\n",
    "    # get the prediction label\n",
    "    print(\"Image ID: {}, Label: {}\".format(inID, label))\n",
    "\n",
    "    # display the predictions with the image\n",
    "    cv2.putText(orig, \"Predicted: {}\".format(label), (10, 30),\n",
    "                cv2.FONT_HERSHEY_PLAIN, 1.5, (43, 99, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Classification\", orig)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Get the bottleneck features and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n",
      "0\n",
      "{}\n",
      "0\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "save_bottlebeck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
